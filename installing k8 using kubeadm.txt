k8-master:  192.168.88.130
k8-worker   192.168.88.131

###############################################################
####################### REBOOTIG SERVER #######################
###############################################################
NOTE: when you use vmware and rebooted the server , kindly use this to make kubectl works:
sudo -i
swapoff -a
exit
strace -eopenat kubectl version


#######################################################################################################
####################### if pods not terminating normally & want to force delete #######################
#######################################################################################################
ON WORKER NODE
sudo apt-get purge --auto-remove apparmor
--------------------
kubectl delete pod NAME --grace-period=0 --force

######################################################################
####################### Access Cluster remotly #######################
######################################################################
ON ADMIN MACHINE
1. install kubectl on admin machine
2. create directory 
mkdir /home/<username>/.kube
ON MASTER NODE
3. copy admin.config file to admin machine
scp /etc/kubernetes/admin.conf username@local_server:/home/<username>/.kube
ON ADMIN MACHINE
4. using the cluster
export KUBECONFIG=/home/<username>/.kube/admin.conf



############################################################################
####################### Install K8 MAster and Worker #######################
############################################################################
https://www.cherryservers.com/blog/install-kubernetes-on-ubuntu
1. disable Swap in master and worker node
#disable it temborary OR
sudo swapoff -a      
#disable it permenently
sudo sed -i '/ swap / s/^/#/' /etc/fstab

2.Update the /etc/hosts File for Hostname Resolution on master and worker (OPTIONAL):
sudo nano /etc/hosts   << add ip and hostname


3.Set up the IPV4 bridge on all nodes master and worker:
cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF

sudo modprobe overlay
sudo modprobe br_netfilter


# sysctl params required by setup, params persist across reboots
cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF


# Apply sysctl params without reboot
sudo sysctl --system


4.Install kubelet, kubeadm, and kubectl on master and worker
#update packages :
sudo apt update


sudo apt-get install -y apt-transport-https ca-certificates curl

this comes by default, just in case run to make sure the directory exist :  sudo mkdir /etc/apt/keyrings
then run:

echo "deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.28/deb/ /" | sudo tee /etc/apt/sources.list.d/kubernetes.list

curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.28/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg

sudo apt-get update

sudo apt install -y kubelet kubeadm kubectl

sudo apt-mark hold kubelet kubeadm kubectl


5.Install Docker on master and worker

sudo apt install docker.io -y

sudo mkdir /etc/containerd

sudo sh -c "containerd config default > /etc/containerd/config.toml"

sudo sed -i 's/ SystemdCgroup = false/ SystemdCgroup = true/' /etc/containerd/config.toml

sudo systemctl restart containerd.service

sudo systemctl restart kubelet.service

sudo systemctl enable kubelet.service


6.Initialize the Kubernetes cluster on the master node

sudo kubeadm config images pull

sudo kubeadm init --pod-network-cidr=10.10.0.0/16


mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

NOTE: after the cluster initilize , it will shows you command to join the worker node , example:

kubeadm join 192.168.88.130:6443 --token yprcrz.5by8hced4kvv484n \
        --discovery-token-ca-cert-hash sha256:56f9f1fbce3144afcc731923d8198a897bd29e9e3524618b3fda2a887fe0cd11
		



		
7.Configure kubectl and Calico on master

kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/tigera-operator.yaml

#download the file:
curl https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/custom-resources.yaml -O

#change the file configuration to change the cidr to the one we used in kubeadm init (step 6 ) , NOTE: you can change the yaml from inside or run this command:
sed -i 's/cidr: 192\.168\.0\.0\/16/cidr: 10.10.0.0\/16/g' custom-resources.yaml

#apply the file to the cluster:
kubectl create -f custom-resources.yaml


8.Add worker nodes to the cluster
NOTE: if you lose the below command you can regenerate it from master node using: kubeadm token create --print-join-command
kubeadm join 192.168.88.130:6443 --token yprcrz.5by8hced4kvv484n \
        --discovery-token-ca-cert-hash sha256:56f9f1fbce3144afcc731923d8198a897bd29e9e3524618b3fda2a887fe0cd11

